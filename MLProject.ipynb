{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP 562 Final Project: Facial Landmark Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of the project is to build a CNN model to detect facial landmark given a human face image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, History\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and augumenting data\n",
    "The pickle file stores the images and the corresponding facial landmarks that was preprocessed using the code in the preprocessing folder. The size of X_train is 3148*160*160*3, which means there are 3148 RGB images whose size are 160*160. The size of Y_train is 3148*136, which stores the 68 keypoints of those 3148 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unpickled_df = pd.read_pickle(\"/300W_train_160by160.pickle\")\n",
    "\n",
    "X_train0 = unpickled_df['X']\n",
    "Y_train0 = unpickled_df['Y']['kpt_norm']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentaion\n",
    "Howerver, for a project like this, 3148 is not large enough to train a strong model. So we need to apply some tricks to create more data. Here we use noising and bluring. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentation: noisy\n",
    "temp1 = X_train0.copy()\n",
    "for t in range(3148):\n",
    "    noise = np.random.randint(20, size = (160,160, 3), dtype = 'uint8')\n",
    "    temp = temp1[t]\n",
    "    for i in range(160):\n",
    "        for j in range(160):\n",
    "            for k in range(3):\n",
    "                if (temp[i,j,k] < 235):\n",
    "                    temp[i,j,k] += noise[i,j,k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First Attempt: structures similar with VGG/AlexNet \n",
    "This is the first attempt, I designed models that similar with VGG and ALexNet, but both are not working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=96, kernel_size=11, activation='relu', input_shape=(160, 160,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=11, strides=(1,1), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "model.add(Conv2D(filters=384, kernel_size=11, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=384, kernel_size=11, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=256, kernel_size=11, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(4096, activation='relu',kernel_initializer='glorot_normal'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(4096, activation='relu',kernel_initializer='glorot_normal'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(1000, activation='relu',kernel_initializer='glorot_normal'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(136, activation='softmax'))\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "hist = History()\n",
    "epochs = 150\n",
    "batch_size = 64\n",
    "\n",
    "#sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='weights.final_2.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "## TODO: Compile the model\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=adam, loss='mean_absolute_percentage_error', metrics=['accuracy'])\n",
    "\n",
    "hist_final = model.fit(X_train0, Y_train0, validation_split=0.2,\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer, hist,tbCallBack], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt2: A shallow model that detects 68 points at a same time\n",
    "This is a shallower CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=3, activation='relu', input_shape=(160, 160,3)))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(512, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(256, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(256, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(512, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(136))\n",
    "\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()\n",
    "\n",
    "hist = History()\n",
    "epochs = 150\n",
    "batch_size = 64\n",
    "\n",
    "#sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='weights.final_2.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "## TODO: Compile the model\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=adam, loss='mean_absolute_percentage_error', metrics=['accuracy'])\n",
    "\n",
    "hist_final = model.fit(X_train0, Y_train0, validation_split=0.2,\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer, hist,tbCallBack], verbose=1)\n",
    "\n",
    "\n",
    "model.save('att2.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attempt3: Divide and conquer:\n",
    "Using 4 models, each only detect some small number of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model one, for the first 17 points\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=3, activation='relu', input_shape=(160, 160,3)))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(512, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(256, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(256, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(256, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(512, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(34))\n",
    "\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()\n",
    "\n",
    "hist = History()\n",
    "epochs = 80\n",
    "batch_size = 64\n",
    "\n",
    "#sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='weights.final_2.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "## TODO: Compile the model\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=adam, loss='mean_absolute_percentage_error', metrics=['accuracy'])\n",
    "\n",
    "hist_final = model.fit(X_train0, Y_train1, validation_split=0.2,\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer, hist,tbCallBack], verbose=1)\n",
    "\n",
    "\n",
    "model.save('m1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 2, for 10 points on the eyebrow\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=3, activation='relu', input_shape=(160, 160,3)))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(512, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(256, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(256, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(256, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(512, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(20))\n",
    "\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()\n",
    "\n",
    "hist = History()\n",
    "epochs = 150\n",
    "batch_size = 64\n",
    "\n",
    "#sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='weights.final_2.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "## TODO: Compile the model\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=adam, loss='mean_absolute_percentage_error', metrics=['accuracy'])\n",
    "\n",
    "hist_final = model.fit(X_train0, Y_train2, validation_split=0.2,\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer, hist,tbCallBack], verbose=1)\n",
    "\n",
    "\n",
    "model.save('m2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 3, for eyes and nose\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=3, activation='relu', input_shape=(160, 160,3)))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(512, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(256, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(256, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(256, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(512, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(42))\n",
    "\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()\n",
    "\n",
    "hist = History()\n",
    "epochs = 150\n",
    "batch_size = 64\n",
    "\n",
    "#sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='weights.final_2.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "## TODO: Compile the model\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=adam, loss='mean_absolute_percentage_error', metrics=['accuracy'])\n",
    "\n",
    "hist_final = model.fit(X_train0, Y_train3, validation_split=0.2,\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer, hist,tbCallBack], verbose=1)\n",
    "\n",
    "\n",
    "model.save('m3.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fourth model, for mouth\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters=16, kernel_size=3, activation='relu', input_shape=(160, 160,3)))\n",
    "\n",
    "model.add(Conv2D(filters=16, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "\n",
    "model.add(Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=2))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(512, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(256, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(256, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(256, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(512, activation='relu',kernel_initializer='glorot_normal'))\n",
    "\n",
    "model.add(Dense(40))\n",
    "\n",
    "\n",
    "# Summarize the model\n",
    "model.summary()\n",
    "\n",
    "hist = History()\n",
    "epochs = 150\n",
    "batch_size = 64\n",
    "\n",
    "#sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='weights.final_2.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "## TODO: Compile the model\n",
    "adam = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "model.compile(optimizer=adam, loss='mean_absolute_percentage_error', metrics=['accuracy'])\n",
    "\n",
    "hist_final = model.fit(X_train0, Y_train4, validation_split=0.2,\n",
    "          epochs=epochs, batch_size=batch_size, callbacks=[checkpointer, hist,tbCallBack], verbose=1)\n",
    "\n",
    "\n",
    "model.save('m4.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict and plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=plt.imread(\"/content/ro160.jpg\")\n",
    "im = np.zeros((1,160,160,3))\n",
    "im[0,:,:,:] = img[:]\n",
    "points = model.predict(im)\n",
    "plt.imshow(img)\n",
    "for i in range(int(len(points[0])/2)):\n",
    "    plt.plot(points[0][2*i]*160,points[0][2*i+1]*160,'ro')\n",
    "from keras.models import load_model\n",
    "img=plt.imread(\"/content/ro160.jpg\")\n",
    "im = np.zeros((1,160,160,3))\n",
    "im[0,:,:,:] = img[:]\n",
    "model1 = load_model('my_model_final.h5')\n",
    "model2 = load_model('my_model_final2.h5')\n",
    "model3 = load_model('my_model_final3.h5')\n",
    "model4 = load_model('my_model_final4.h5')\n",
    "point1 = model1.predict(im)\n",
    "point2 = model2.predict(im)\n",
    "point3 = model3.predict(im)\n",
    "point4 = model4.predict(im)\n",
    "plt.imshow(img)\n",
    "for i in range(int(len(point1[0])/2)):\n",
    "    plt.plot(point1[0][2*i]*160,point1[0][2*i+1]*160,'ro')\n",
    "for i in range(int(len(point2[0])/2)):\n",
    "    plt.plot(point2[0][2*i]*160,point2[0][2*i+1]*160,'ro')\n",
    "for i in range(int(len(point3[0])/2)):\n",
    "    plt.plot(point3[0][2*i]*160,point3[0][2*i+1]*160,'ro')\n",
    "for i in range(int(len(point4[0])/2)):\n",
    "    plt.plot(point4[0][2*i]*160,point4[0][2*i+1]*160,'ro')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
